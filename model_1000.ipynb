{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d673e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, directory, tokenizer, max_length=512):\n",
    "        self.examples = []\n",
    "\n",
    "        for label_dir in ['pos', 'neg']:\n",
    "            label = 1 if label_dir == 'pos' else 0\n",
    "            subdir = os.path.join(directory, label_dir)\n",
    "            for filename in os.listdir(subdir):\n",
    "                file_path = os.path.join(subdir, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read().strip()\n",
    "                    inputs = tokenizer(text, max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "                    self.examples.append((inputs.input_ids, inputs.attention_mask, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask, label = self.examples[idx]\n",
    "        return {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask), 'labels': torch.tensor(label)}\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "\n",
    "\n",
    "train_dataset = ReviewsDataset(r\"C:\\Users\\shital.nerkar\\Desktop\\SentimentAnalysis\\reviews_SA\\data\\train\",tokenizer)\n",
    "test_dataset = ReviewsDataset(r\"C:\\Users\\shital.nerkar\\Desktop\\SentimentAnalysis\\reviews_SA\\data\\test\",tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d03ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2cc98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 5:20:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.3182547607421875, metrics={'train_runtime': 19261.9428, 'train_samples_per_second': 0.208, 'train_steps_per_second': 0.026, 'total_flos': 1052444221440000.0, 'train_loss': 0.3182547607421875, 'epoch': 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Where to store the final model\n",
    "    num_train_epochs=2,              # Total number of training epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=100,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.05,               # Weight decay if applied\n",
    "#     logging_dir='./logs',         \n",
    "#     logging_steps=10,\n",
    "    no_cuda=True                     # Set this to False to use CUDA if available\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30a53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 03:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5006716847419739, 'eval_runtime': 252.8828, 'eval_samples_per_second': 0.807, 'eval_steps_per_second': 0.051, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad90ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: Negative\n",
      "Probabilities: [0.9979313611984253, 0.0020686383359134197]\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, model, tokenizer):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model.to('cpu')  \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    prediction = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    sentiments = [\"Negative\", \"Positive\"]  \n",
    "    predicted_sentiment = sentiments[prediction]\n",
    "\n",
    "    probabilities = probabilities.numpy().flatten().tolist()\n",
    "\n",
    "    return predicted_sentiment, probabilities\n",
    "\n",
    "text = '''\n",
    "Het horloge is net aangekomen en na het opladen begon ik met het koppelingsproces.\n",
    "Wat mij is opgevallen en wat zo vervelend is, is het feit dat het horloge zichzelf blijft bellen, waardoor de gebruikersinterface niet zo soepel verloopt.\n",
    "Dus onder mijn verwachtingen!\n",
    "Nu weet ik niet meer wat ik ermee ga doen!\n",
    "'''\n",
    "\n",
    "# \"\"\"\n",
    "# Het horloge heeft een goed prijs kwaliteit verhouding met verbazingwekkend veel functies! \n",
    "# De bouwkwaliteit is top en alles werkt goed en soepel. \n",
    "# Verder had ik ook wat vragen over het gebruik van het horloge, en het support team hielp mij hier snel en goed mee!\n",
    "# \"\"\"\n",
    "\n",
    "predicted_sentiment, probabilities = predict_sentiment(text, model, tokenizer)\n",
    "print(f\"Predicted sentiment: {predicted_sentiment}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4581ca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Negative\n",
      "Probabilities: [0.991441547870636, 0.008558427914977074]\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_from_file(file_path, model, tokenizer):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    predicted_sentiment, probabilities = predict_sentiment(text, model, tokenizer)\n",
    "\n",
    "    return predicted_sentiment, probabilities\n",
    "\n",
    "file_path = r\"C:\\Users\\shital.nerkar\\Desktop\\SentimentAnalysis\\DatchData\\DBRD_v3\\DBRD\\test\\pos\\22243_5.txt\"\n",
    "\n",
    "predicted_sentiment, probabilities = predict_sentiment_from_file(file_path, model, tokenizer)\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
